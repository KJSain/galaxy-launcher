---
# tasks file for cronbackupdb

- name: make sure pigz is installed
  package:
    name: pigz
    state: latest

- name: Create backup user that has  access to the postgres database inside the container
  user:
    name: "{{backup_user}}"
    generate_ssh_key: yes
    uid: "{{container_postgres_user}}"
    groups: docker
    state: present
    non_unique: yes #The UID should be set to that of the postgres container user, regardless of other UID's
    ssh_key_file: "{{backup_ssh_key_file}}"

- name: copy public key of backup user to ansible host
  fetch:
    dest: "files/{{inventory_hostname}}/{{backup_user}}_public-key/id_rsa.pub"
    flat: yes
    src: "/home/{{backup_user}}/{{backup_ssh_key_file}}.pub"
    validate_checksum: yes

- name: create backup folder with logs and scripts subfolders
  file:
    path: "{{item}}"
    state: directory
    owner: "{{backup_user}}"
    group: "{{backup_user}}"
    mode: 0700
  with_items:
    - "{{backup_location}}"
    - "{{backup_location}}/logs"
    - "{{backup_location}}/scripts"
    
- name: create folder for each job within the backup folder
  file:
    path: "{{backup_location}}/{{item.key}}"
    state: directory
    owner: "{{backup_user}}"
    group: "{{backup_user}}"
    mode: 0700
  with_dict: "{{ backupdb_cron_jobs }}"

- name: Create backup scripts for each job
  template:
    src: "backupscript.sh.j2"
    dest: "{{backup_location}}/scripts/{{item.key}}-backupscript.sh"
    owner: "{{backup_user}}"
    group: "{{backup_user}}"
    mode: 0700
  vars:
    backup_archive: "{{item.value.filename}}$(TZ='UTZ' date +'{{item.value.timestamp}}').gz"
    backup_db_location: "{{backup_location}}/{{item.key}}"
    files_to_keep: "{{item.value.files_to_keep}}"
    compression_level: "{{item.value.compression_level | default(6)}}"
    compression_threads: "{{item.value.compression_threads | default(4)}}"
  with_dict: "{{ backupdb_cron_jobs }}"
 
- name: set jobs in cron
  cron:
    job: "bash {{backup_location}}/scripts/{{item.key}}-backupscript.sh >> {{log_file}} 2>&1"
    state: present
    user: "{{backup_user}}"
    backup: yes
    name: "{{item.value.description}}"
    month: "{{item.value.cron.month | default(omit)}}"
    day: "{{item.value.cron.day | default(omit)}}"
    weekday: "{{item.value.cron.weekday | default(omit)}}"
    hour: "{{item.value.cron.hour | default(omit)}}"
    minute: "{{item.value.cron.minute | default(omit)}}"
    special_time: "{{item.value.cron.special_time | default(omit)}}" 
  vars:
    log_file: "{{backup_location}}/logs/{{item.key}}.log"   
  with_dict: "{{ backupdb_cron_jobs }}"

- name: Set job in cron to rsync backups to a remote location
  cron:
    job: "stdbuf -oL {{rsync_command | replace('\n', '')}} | {{read_stdout}} &>> {{rsync_log}} "
    state: present
    user: "{{backup_user}}"
    backup: yes
    name: "Rsync to the backup host"
    month: "{{item.cron.month | default(omit) }}"
    day: "{{item.cron.day | default(omit) }}"
    weekday: "{{item.cron.weekday | default(omit)}}"
    hour: "{{item.cron.hour | default(omit)}}"
    minute: "{{item.cron.minute | default(omit)}}"
    special_time: "{{item.cron.special_time | default(omit)}}"
  
  vars:
    rsync_command: > 
      rsync -a {{ (item.delete == True ) | ternary ('--delete','') }}
      --compress-level={{item.compression_level}}
      {{backup_location}} {{item.dest}}
    rsync_log: "{{backup_location}}/logs/rsync.log"
    read_stdout: 'while IFS= read -r line; do echo "$({{cronbackupdb_log_timestamp}}) $line" ; done'
  with_items:
    - "{{backup_galaxy_rsync_settings}}"
